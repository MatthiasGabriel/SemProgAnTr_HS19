\section{Concolic Testing} \label{section:concolic_testing}
Concolic execution tries to overcome the restrictions of symbolic execution, that were discussed in \ref{section:symbolic_restrictions}. There are many different approaches to do this, but all trade in some of the completeness to be able to fulfil at least a partial analysis of the program.
Based on KLEE \cite{Cadar:2008:KUA:1855741.1855756} one possible approach to these two problems will be presented in this section.

\subsection{Main approaches of KLEE}
KLEE only works on programs that are first compiled into the LLVM, an assembly language. This is normally done by using the compiler Clang. Clang is currently able to compile C, C++  and Objective-C programs into LLVM.
Each of the states that we saw in the previous examples \ref{fig:sym_example_one} and \ref{fig:sym_tree_loop} has the properties $\sigma$, now called heap, and $\pi$, which is called path condition. Additionally, each state has a register file, a stack, and an instruction pointer. Based on the current instruction that is processed, KLEE either modifies $\sigma$ or $\pi$ as we saw in the previous chapters.

If the statement needs a modification of $\sigma$, the instruction gets mapped into an identitcal symbolic instruction. For most instructions the symbolic execution is trivial. For example the result of an addition of two symbolic values is just the addition of the two values and will not get simplified during the operation. After applying the following instruction the $\%dst$ register contains the expression $Add(\%src0, \%src1)$\footnote{This exact example was originally described in \cite{Cadar:2008:KUA:1855741.1855756}}
$$\%dst = add\text{ }i32\text{ }\%src0,\text{ }\%src1$$
Note however that KLEE executes the operation directly if all input values are concrete and therefore assigns a new concrete value to the variable.\todo{non trivial instructions}
Assume the current variable assignments $a = 5$, $\b = \alpha_b$ and $c=\alpha_c$. If the statement $a = a + 10$ gets executed, the value of $5 + 10$ has to be calculated and leads to $a = 15$, however the statement $b = b + c$ leads to $b = \alpha_b + \alpha_c$

If it is a branching statement, $\pi_{true}$ as well as $\pi_{false}$ are calculated. A duplication of the current state takes place after the two $\pi$ are checked for feasibility in combination with the current path condition.

This process continues until all branches are processed or a defined timer is reached. In smaller applications, it's still possible to reach all possible states and therefore reach completeness. In more complex applications it's required to optimize the scheduling \ref{section:state_scheduling} to reach the best possible coverage of states before the timer hits the defined limit.
\subsubsection{Approach for dangerous operations}\label{section:dangerous_operations}
In addition to branching statements, each potentially dangerous operation, such as pointer dereference, array access, division operations, modulo operations and assert statements, generates a new branch too. With this additional branching step it's possible to automatically check if any input is possible, which results in an invalid operation. This state never has a subtree attached. If the path condition is infeasible the execution stops automatically, before the branching takes place. However, if it's feasible, an error is raised resulting in the cancellation of this subtree. On the other branch, the negative of the condition is added to prevent the error in this state and to be able to continue the analysis of the program.

The only special cases of these dangerous operations are loading and storing operations. KLEE maps every object to a STP specific array. This enables STP to ignore the parts of the state data, which are not directly related to the expression that gets evaluated. Since it could be possible that a "symbolic" pointer refers to different objects, the state will be cloned for each of the objects as soon as the pointer gets dereferenced. With the cloning it can be ensured that in every state the pointer references exactly one specific object. This may seem very pricy, as for each possible object a new state has to be created. However, in reality, semantic pointers to multiple objects rarely happen. 

\subsubsection{State management}
As there are many states created and even hold during the execution, KLEE tries to minimize both the creation time of a new state as well as the memory footprint. It does this by taking advantage of the big redundancy that these states have because they are often related and only differ in some of their properties. To be able to use this redundancy KLEE treats all memory objects as immutable and thus can reuse them as often as required. The consequence of this property is that whenever an object has to be modified it needs to be copied. This process is also called copy-on-write.

\subsubsection{State scheduling}\label{section:state_scheduling}
Even if the states are very slim and efficiently created depending on the order of the computation, the computation engine could be blocked by a single loop, leading to the starvation of other states. Assume a very simplistic depth-first approach that first creates the two related states on every branching condition and after that processes the state that fulfils the branching condition. In the example with a loop \ref{fig:sym_tree_loop} the engine would always process the left child and no output would be generated at all. State C and State G would be constructed but never analyzed and therefore no return statement would be reached.

To prevent this, KLEE implements two different kinds of scheduling algorithms. 

Random Path Selection organises the states in a binary tree, as visualised by the previous examples, but instead of just going depth-first at the current path, the algorithms randomly selects which path to go when traversing the tree. After each execution of a state, the traversing starts at the top again and thus favours unprocessed states that are higher up in the tree as visualized in figure \ref{fig:state_tree_probability}. Because of this, the starvation of states is no longer possible. A nice side effect of this selection is, that the conditions in higher states are smaller and therefore the processing takes less effort.

Coverage-Optimized Search is the second algorithm that is included in KLEE. As its name suggests, it tries to maximize the coverage. It uses different heuristics to determine how probable it is to reach currently uncovered code in the next few steps. After that it randomly selects the branch based on this probability, preferring states with higher probability.
To benefit from the positive features of both algorithms KLEE normally uses them in a round-robin manner. Because the scheduling is very much dependent on the analysed software and another scheduling algorithm may deliver better results, KLEE allows other state scheduling mechanisms to be used.
\begin{figure}
\begin{tikzpicture}[
    grow=down,
  baseline,
  level distance=25mm,
  text depth=.1em,
  text height=.8em,
  scale = 1,
  level 1/.style={sibling distance=11em},
  level 2/.style={sibling distance=10em},
    edge from parent/.style={very thick,draw=blue!40!black!60,
        shorten >=5pt, shorten <=5pt},
    edge from parent path={(\tikzparentnode.south) -- (\tikzchildnode.north)},
    kant/.style={text width=2cm, text centered},
    straight/.style={text width=2cm},
    every node/.style={text ragged, inner sep=2mm},
    pending/.style={rectangle, rounded corners, shade, top color=white,
    bottom color=blue!50!black!20, draw=blue!40!black!60, very
    thick },
    analysed/.style={rectangle, rounded corners, shade, top color=blue!50!black!20,
    bottom color=blue!50!black!40, draw=blue!40!black!60, very
    thick }
    ]

\node[analysed] [rectangle split, rectangle split, rectangle split parts=1, text ragged] {
   	 \textbf{State A}}
child {
	        node[analysed] [rectangle split, rectangle split, rectangle split parts=1, text ragged] {
		\textbf{State B}
	        }
child {
	        node[pending] [rectangle split, rectangle split, rectangle split parts=2, text ragged] {
		\textbf{State F}
		\nodepart{second}
   		0.5
	        }
        edge from parent
            node[straight, right, midway] {1.0}}
        edge from parent
            node[kant, below, pos=.4] {0.5}}
child {
	        node[analysed] [rectangle split, rectangle split, rectangle split parts=1, text ragged] {
		\textbf{State C}
	        }
child {
	        node[pending] [rectangle split, rectangle split, rectangle split parts=2, text ragged] {
		\textbf{State D}		
		\nodepart{second}
   		0.25
	        }
        edge from parent
            node[kant, below, pos=.4] {0.5}}
child {
	        node[pending] [rectangle split, rectangle split, rectangle split parts=2, text ragged] {
		\textbf{State E}
		\nodepart{second}
   		0.25
	        }
        edge from parent
            node[kant, below, pos=.4] {0.5}}
        edge from parent
            node[kant, below, pos=.4] {0.5}};

\end{tikzpicture}
\caption{Binary state tree with the chance to get selected. On the edge the relative chance is given, which is normally either 1 or 0.5 based on the above statement.}
\label{fig:state_tree_probability}
\end{figure}
\subsubsection{Query optimization}
Since KLEE sends many and very complex queries to STP, the computation time of these queries takes the majority of the time when executing an analysis. To reduce the computational time and thus be able to finish the analysis faster or at least cover more states in the same time window, different optimizations are applied before a query gets solved by STP. 
At the start of these optimizations KLEE tries to do arithmetic simplifications($5*\alpha_a + 2*(4-\alpha_a) = 3 * \alpha_a + 8$). These rewritings are always related to exactly one condition of the whole path condition or one variable entry in the memory.

The second and third optimization exploit the additional information that arises from equality constraints. In the so-called Constraint Set Simplification KLEE tries to simplify the whole path condition by replacing symbolic values if such a new equality constraint is added. Previous conditions can often be eliminated or at least simplified. 
Assume the following path condition $\pi = \{\alpha_a < 100, \alpha_b - \alpha_a< 20\}$. If a new constraint $\alpha_a = 10$ is added, the whole path condition can be simplified to $\pi = \{\alpha_a = 10, \underbrace{10 < 100}_{true},\underbrace{\alpha_b - 10 < 20}_{\alpha_b < 30}\}$. Instead of having three conditions with relations to each other, the optimization results in two simple conditions and true, which will be eliminated. Additionally the value of $\alpha_a$ in this and following states is actually always exactly $10$ and no longer a symbolic value even if it did not get assigned. This information can be used to update your memory ($\sigma$)

So far the optimizations do simplifications to the path constraint. The next optimization, which is called Constraint Independence, goes further and tries to deliver only a partial set of constraints to STP. It does this by tracking the relations between the different variables. Assume that a third condition $\alpha_c + \alpha_b > 50$ is added to our previous example. The resulting path condition would therefore be $\pi = \{\alpha_a = 10, \alpha_b < 30, \alpha_c + \alpha_b > 50\}$. If the next statement is $assert(c != 20)$, the query to STP would try to negate this assertion condition. Because the condition is not related to $\alpha_a$ the first constraint can be dropped completely for this query. This does not modify the state data, but optimises only one specific query. Note that this constraint only can be dropped because the second optimization removed $\alpha_a$ from the second condition. Otherwise, a relation would still exist.

The last and most complex optimization is called Counter-example Cache. In the cache each constraint set is saved together with a possible variable assignment if the query was successful, otherwise, it will be marked as UNSAT. Before handing over a query to STP the cache is searched for a related superset or subset.

If a superset is found and this superset has a solution, the variable assignment also has to be satisfiable for the current condition set, because the dropping of constraints can never invalidate a solution.

If a subset of the original query set is found and has no solution, this results in an unsatisfiable solution as well. When no solution satisfies the less strict subset, there's no way that any variable assignment can satisfy the queried set, which contains all of the constraints of the subset and some additional constraints.

If a subset is found and has a satisfiable assignment there is a good chance that this solution will also satisfy the new constraint set. Because it is much cheaper to verify if a solution is valid for a specific constraint set, KLEE does exactly that and returns the solution. If the solution is not valid for the new constraint set a query to STP is necessary.

The Counter-example Cache is especially powerful in combination with Constraint Independence because the queried constraint sets get smaller and therefore hit the cache more often.

In all this KLEE does nothing different than specified in the previous chapter \ref{section:symbolic_execution} and implements a specific and efficient memory and state management, query optimization with caching and different state schedulings. But there's an additional topic that is tackled by KLEE.
\subsubsection{Dependency on environment}
Another problem of symbolic execution is the dependency on the environment as discussed in chapter \ref{section:symbolic_restrictions}. KLEE tries to loosen the limitations by introducing so-called Environment Modeling. The idea behind these models is that they substitute the real environment against one that is aware of the symbolic input values. 
This model needs to be able to accept a symbolic value and produce every possible value from it. Additionally, it needs to be aware of the previous modification that the program made on this model, but it's important that the modifications only affect the model in subsequent states. 

During the execution of KLEE, these models will be injected based on the call that was made to the environment. These models are non-trivial to write and require deep knowledge of the original function as they need to behave similar. KLEE already includes a complete model for a symbolic file system and many different system-calls like open, read, write, that operate on this model.
The filesystem model optimises concrete calls by dispatching it to the original function on the real file system if the call contains only concrete arguments. Only when a symbolic value is passed as an argument the related model will be called. It's required to specify the number and size of symbolic files separately when starting a KLEE-analysis so that KLEE is able to allocate the files in the model and point the corresponding variable to the correct file.

At default settings, KLEE's file system model does not produce environmental failures such as disk full. However, it's possible to simulate such failures, based on the requirements for the program. By offering such an option it's in the hands of the user to choose either more completeness or less computational effort. The same method can be applied to any model by only handling the cases which the user of KLEE wants to check. However, he should always remember that by simplifying the model some of the completeness of the analysis vanishes.

If for an external function no model is provided, KLEE will concretize the symbolic call arguments. If this happens, the analysis of the program will not be complete, even if KLEE finishes.
\subsubsection{Test cases}
Whenever a state reaches the end of the program or an error is detected, KLEE generates a test case. This is done by querying STP for a concrete assignment for all symbolic values under the current path condition. If the program is deterministic the execution of the original program with these concrete values will behave exactly as the symbolic execution with this path condition.
Note that depending on the execution mode of KLEE it is no longer required to compile the program to LLVM because KLEE will automatically execute the compiled binary with the appropriate values. This has additional benefits, such as it's easy to measure coverage by using standard tooling such as gcov, or that it is easy to prove that a certain input triggers an error. To prove this a special setup is no longer required, the program has just to be run with the appropriate values.

Executing test cases which use a symbolic model is not trivial, because the environment has to be set up to reflect the symbolic model. Before executing the program KLEE creates the required files, directories, etc and calls the program with the new concrete file locations. Because it is not possible to reproduce an environmental failure, KLEE simulates this case whenever it is required. It uses a debugging tool to return the required error state and does not execute the system call at all.
\subsubsection{Execution of KLEE}
There exist two different modes of how to analyse your program with the help of KLEE. Assume that the function calculateMagicNumber which is defined in code snippet \ref{codeSnippet:symbolicExecution} should be tested.

The first approach is to write a custom main function in which two symbolic variables are defined and call the function with these variables as shown in code snippet \ref{codeSnippet:klee_inline}.
\begin{codesnippet}[caption={Main function which defines two symbolic variables and calls the function calculateMagicNumber of code snippet \ref{codeSnippet:symbolicExecution}}, label={codeSnippet:klee_inline}]
int main() {
  int a;
  klee_make_symbolic(&a, sizeof(a), "a");
  int b;
  klee_make_symbolic(&b, sizeof(b), "b");
  return calculateMagicNumber(a,b);
}
\end{codesnippet}

After the compilation to LLVM with the command \textit{clang -I ../include -c -g -emit-llvm magicnumber\_symbolic.c}, KLEE can be started on the newly generated file with the command \textit{klee --only-output-states-covering-new magicnumber\_symbolic.bc}.

With these settings, KLEE will automatically generate 5 different tests and detect one error. 
The test case which triggered the error contains the concrete values of $a$ and $b$ which trigger the error and can be viewed with the command \textit{ktest-tool klee-last/test<test\_number>.ktest}.
The output is display in code snippet \ref{codeSnippet:test_case_one}.

\begin{codesnippet}[caption={The test case generated by KLEE which triggers the assertion error when executing it on the code snippet \ref{codeSnippet:klee_inline}}, label={codeSnippet:test_case_one}]
ktest file : 'klee-last/test000001.ktest'
args       : ['magicnumber_symbolic.bc']
num objects: 3
object 0: name: 'model_version'
object 0: size: 4
object 0: data: b'\\x01\\x00\\x00\\x00'
object 0: hex : 0x01000000
object 0: int : 1
object 0: uint: 1
object 0: text: ....
object 1: name: 'a'
object 1: size: 4
object 1: data: b'\\x00\\x00\\x00\\x00'
object 1: hex : 0x00000000
object 1: int : 0
object 1: uint: 0
object 1: text: ....
object 2: name: 'b'
object 2: size: 4
object 2: data: b'\\x00\\x00\\x00\\x00'
object 2: hex : 0x00000000
object 2: int : 0
object 2: uint: 0
object 2: text: ....
\end{codesnippet}

The second approach is to use a main function which takes the arguments from the command line and calls the function with the parsed input as shown in code snippet \ref{codeSnippet:klee_arguments}.
In this approach, it's no longer required to define in the program code which arguments should be treated as symbolic values. Additionally, the code has no longer a dependency on the program code of KLEE.

\begin{codesnippet}[caption={Main function which parses two input arguments and calls the function calculateMagicNumber of code snippet \ref{codeSnippet:symbolicExecution}}, label={codeSnippet:klee_arguments}]
int main(int argc, char **argv) {
  if(argc != 3){
	return -1;
  }
  int a = atoi(argv[1]);
  int b = atoi(argv[2]);
  return calculateMagicNumber(a,b);
}
\end{codesnippet}

The compilation is nearly the same as before \textit{clang -c -g -emit-llvm magicnumber\_args.c} but the additional include of KLEE can be omitted because no klee\_make\_symbolic is no longer used.

KLEE gets called a bit differently: \textit{klee -posix-runtime -libc=uclibc --only-output-states-covering-new magicnumber\_args.bc -sym-args 1 3 4}.
The additional option \textit{-posix-runtime} is required when using symbolic arguments, the parameter \textit{-libc=uclibc} replaces the default libc with the prepacked libc of KLEE, which allows the \textit{atoi} function to work with symbolic values.
With the parameter \textit{-sym-args 1 3 4} KLEE knows how many symbolic values of which maximum length it needs to generate. In our case, KLEE tries different combinations of one to three arguments with a maximum length of four characters.
When executed with these settings KLEE detects the error too. However, due to the additional complexity of the external function \textit{atoi} the execution of KLEE covers much more paths and generates around 15 tests. The execution therefore takes much longer.

The comparison of the two test cases shows that the inputs that triggered the error are not equal.
Because it's not possible to restrict the input variables to integers the generated concrete values are char-arrays, which in the program code will be converted into integers.

\begin{codesnippet}[caption={The test case generated by KLEE which triggers the assertion error when executing it on the code snippet \ref{codeSnippet:klee_arguments}}, label={codeSnippet:test_case_two}]
ktest file : 'klee-last/test000006.ktest'
args       : ['magicnumber_args.bc',
              '-sym-args', '1', '3', '4']
num objects: 4
object 0: name: 'n_args'
object 0: size: 4
object 0: data: b'\x02\x00\x00\x00'
object 0: hex : 0x02000000
object 0: int : 2
object 0: uint: 2
object 0: text: ....
object 1: name: 'arg00'
object 1: size: 5
object 1: data: b'\x00\x00 \x00\x00'
object 1: hex : 0x0000200000
object 1: text: .. ..
object 2: name: 'arg01'
object 2: size: 5
object 2: data: b'\x00\x00\x00 \x00'
object 2: hex : 0x0000002000
object 2: text: ... .
object 3: name: 'model_version'
object 3: size: 4
object 3: data: b'\x01\x00\x00\x00'
object 3: hex : 0x01000000
object 3: int : 1
object 3: uint: 1
object 3: text: ....
\end{codesnippet}

One major benefit of using the symbolic arguments in comparison to the symbolic variables is that it's possible to replay the test cases on any executable.
This allows it to compile an independent executable from the source code and measure the code coverage without a direct dependency on the KLEE engine.

\subsubsection{Software Equivalence}\label{section:software_equivalence}
In addition to testing a program, KLEE can also be used to reason about the equivalence of two implementations. Assume two functions $f(x)$ and $f'(x)$ which should be equivalent. With a simple assert statement $assert(f(x) == f'(x))$ where $x$ is a symbolic input, KLEE will execute try to find an assignment such that $f(x) != f'(x)$.

If any assignment is found the symbolic variable will be concretised, otherwise it's proven that the two functions are equivalent. Note however that this requires KLEE to be able to evaluate all possible states of $f(x)$ and $f'(x)$ without exceeding the specified time limit.
\subsection{Other approaches}
In this chapter, I want to discuss different search strategies discussed in \cite{SurveySymExec-CSUR18}

Dynamic Symbolic Execution: Use a concrete input to "drive" the execution and after completion try to modify the concrete input by changing it based on the conditions. \cite{Godefroid:2005:DDA:1064978.1065036}

SelectiveSymbolicExecution: Execute only parts of the program symbolically. Other parts(for example subroutines, etc) are executed concretely. This can have a big impact on the soundness and completeness. \cite{Chipounov:2012:SPD:2110356.2110358}
\todo{add other search strategies that are not used in KLEE}