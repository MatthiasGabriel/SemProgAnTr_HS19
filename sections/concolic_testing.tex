\section{Concolic Testing} \label{section:concolic_testing}
Concolic execution tries to overcome the restrictions of symbolic execution, that were discussed in \ref{section:symbolic_restrictions}. There are many different approaches to do this, but all of them trade in some of the completeness to be able to fulfill at least a partial analysis of the program.
On the basis of KLEE \cite{Cadar:2008:KUA:1855741.1855756} one possible approach to these two problems will be presented in this section.

\subsection{Main approaches of KLEE}
KLEE only works on programs that are first compiled into the LLVM, an assembly language. This is normally done by using the compiler Clang\footnote{Clang is currently able to compile C, C++  and Objective-C programs into LLVM.}. 
Each of the states that we saw in the previous examples \ref{fig:sym_example_one} and \ref{fig:sym_tree_loop} has the properties $\sigma$, now called heap, and $\pi$, which is called path condition. Additionally each state has a register file, a stack and an instruction pointer. Based on the current instruction that is processed, KLEE either modifies $\sigma$ or $\pi$ as we saw in the previous chapters.

If the statement needs a modification of $\sigma$, the instruction gets mapped into an identitcal symbolic instruction. For most instructions the symbolic execution is trivial. For example the result of an addition of two symbolic values is just the addition of the two values and will not get simplified during the operation.\todo{non trivial instructions} Note however that KLEE executes the operation directly if all input values are concrete and therefore assigns a new concrete value to the variable.
Assume the current variable assignments $a = 5$, $\b = \alpha_b$ and $c=\alpha_c$. If the statement $a = a + 10$ gets executed, the value of $5 + 10$ has to be calculated and leads to $a = 15$, however the statement $b = b + c$ leads to $b = \alpha_b + \alpha_c$

If it is a branching statement, $\pi_{true}$ as well as $\pi_{false}$ are calculated. A duplication of the current state takes place after the two $\pi$ are checked for feasability in combination with the current path condition.

This process continues until all branches are processed or a defined timer is reached. In smaller applications it's still possible to reach all possible states and therefore reach completeness. In more complex applications it's required to optimize the scheduling \ref{section:state_scheduling} to reach the best possible coverage of states before the timer hits the defined limit.
\subsubsection{Approach for dangerous operations}
In addition to branching statements each potentially dangerous operation, such as pointer dereferencing or division, generates a new branch too. With this additional branching step it's possible to automatically check if any input is possible, that results in an invalid operation. This state never has a subtree attached. If the path condition is infeasable the execution stops automatically, before the branching actually takes place. However if it's feasable, an error is raised resulting in the cancelation of this subtree. On the other branch the negative of the condition is added to prevent the error in this state and to be able to continue the analysis of the program.

The only special case of these dangerous operations are loading and storing operations. KLEE maps every object to a STP specific array. This enables STP to ignore the parts of the state data, which are not directly related to the expression that gets evaluated. Since it could be possible that a "symbolic" pointer refer to different objects, the state will be cloned for each of the objects as soon as the pointer gets dereferenced. With the cloning it can be ensured that in every state the pointer references exactly one specific object. This may seem very pricy, as for each possible object a new state has to be created. However in reality semantic pointers to multiple objects rarely happen. 

\subsubsection{State management}
As there are many states created and even hold during the execution, KLEE tries to minimize both the creation time of a new state as well as the memory footprint. It does this by taking advantage of the big redundancy that these states have, because they are often related and only differ in some of their properties. To be able to use this redundancy KLEE treats all memory objects as immutable and thus can reuse them as often as required. The consequence of this property is that whenever an object has to be modified it needs to be copied. This process is also called copy-on-write.

\subsubsection{State scheduling}\label{section:state_scheduling}
Even if the states are very slim and efficiently created depending on the order of the computation the computation engine could be blocked by a single loop, leading to starvation of other states. Assume a very simplistic depth-first approach that first creates the two related states on every branching condition and after that processes the state that fulfills the branching condition. In the example with a loop\ref{fig:sym_tree_loop} the engine would always process the left child and no output would be generated at all\footnote{State C and State G would be constructed but never analyzed and therefore no return statement would be reached.}.

To prevent this, KLEE implements two different kinds of scheduling algorithms. 

Random Path Selection organises the states in a binary tree, as visualised by the previous examples, but instead of just going depth-first at the current path, the algorithm randomly selects which path to go when traversing the tree. After each execution of a state the traversing starts at the top again and thus favors unprocessed states that are higher up in the tree as visualized in figure \ref{fig:state_tree_probability}. Because of this, starvation of states is no longer possible. A nice side effect of this selection is, that the conditions in higher states are smaller and therefore the processing takes less effort.

Coverage-Optimized Search is the second algorithm that is included in KLEE. As its name suggests, it tries to maximize the coverage. It uses different heuristics to determine how probable it is to reach currently uncovered code in the next few steps. After that it randomly selects the branch based on this probability, preferring states with higher probability.
To benefit from the positive features of both algorithm KLEE normally uses them in round-robin manner\footnote{Note that the scheduling is very much dependent on the analysed software. It's possible that another scheduling algorithm delivers better results for a specific program. For that reason KLEE allows other state scheduling mechanisms to be used.}.
\begin{figure}
\begin{tikzpicture}[
    grow=down,
  baseline,
  level distance=25mm,
  text depth=.1em,
  text height=.8em,
  scale = 1,
  level 1/.style={sibling distance=11em},
  level 2/.style={sibling distance=10em},
    edge from parent/.style={very thick,draw=blue!40!black!60,
        shorten >=5pt, shorten <=5pt},
    edge from parent path={(\tikzparentnode.south) -- (\tikzchildnode.north)},
    kant/.style={text width=2cm, text centered},
    straight/.style={text width=2cm},
    every node/.style={text ragged, inner sep=2mm},
    pending/.style={rectangle, rounded corners, shade, top color=white,
    bottom color=blue!50!black!20, draw=blue!40!black!60, very
    thick },
    analysed/.style={rectangle, rounded corners, shade, top color=blue!50!black!20,
    bottom color=blue!50!black!40, draw=blue!40!black!60, very
    thick }
    ]

\node[analysed] [rectangle split, rectangle split, rectangle split parts=1, text ragged] {
   	 \textbf{State A}}
child {
	        node[analysed] [rectangle split, rectangle split, rectangle split parts=1, text ragged] {
		\textbf{State B}
	        }
child {
	        node[pending] [rectangle split, rectangle split, rectangle split parts=2, text ragged] {
		\textbf{State F}
		\nodepart{second}
   		0.5
	        }
        edge from parent
            node[straight, right, midway] {1.0}}
        edge from parent
            node[kant, below, pos=.4] {0.5}}
child {
	        node[analysed] [rectangle split, rectangle split, rectangle split parts=1, text ragged] {
		\textbf{State C}
	        }
child {
	        node[pending] [rectangle split, rectangle split, rectangle split parts=2, text ragged] {
		\textbf{State D}		
		\nodepart{second}
   		0.25
	        }
        edge from parent
            node[kant, below, pos=.4] {0.5}}
child {
	        node[pending] [rectangle split, rectangle split, rectangle split parts=2, text ragged] {
		\textbf{State E}
		\nodepart{second}
   		0.25
	        }
        edge from parent
            node[kant, below, pos=.4] {0.5}}
        edge from parent
            node[kant, below, pos=.4] {0.5}};

\end{tikzpicture}
\caption{Binary state tree with the chance to get selected. On the edge the relative chance is given, which is normally either 1 or 0.5 based on the above statement.}
\label{fig:state_tree_probability}
\end{figure}
\subsubsection{Query optimization}
Since KLEE sends many and very complex queries to STP, the computation time of these queries takes the majority of time when executing an analysis. To reduce the computational time and thus be able to finish the analyis faster or at least cover more states in the same time, different optimizations are applied before a query gets really solved by STP. 
At the start of these optimizations KLEE tries to do arithmetic simplifications($5*\alpha_a + 2*(4-\alpha_a) = 3 * \alpha_a + 8$). These rewritings are always related to exactly one condition of the whole path condition or one variable entry in the memory.

The second and third optimization exploit the additional information that arise from equality constraints. In the so called Constraint Set Simplification KLEE tries to simplify the whole path condition by replacing symbolic values if such a new equality constraint is added. Previous conditions can often be eliminated or at least simplified. 
Assume the following path condition $\pi = \{\alpha_a < 100, \alpha_b - \alpha_a< 20\}$. If a new constraint $\alpha_a = 10$ is added, the whole path condition can be simplified to $\pi = \{\alpha_a = 10, \underbrace{10 < 100}_{true},\underbrace{\alpha_b - 10 < 20}_{\alpha_b < 30}\}$. Instead of having three conditions with relations to each other, the optimization results in two simple conditions and true, which will be eliminated. Additionally the value of $\alpha_a$ in this and following states is actually always exactly $10$ and no longer a symbolic value even if it did not get assigned. This information can be used to update your memory ($\sigma$)

So far the optimizations do simplifications to the path constraint. The next optimization, which is called Constraint Independence, goes further and tries to deliver only a partial set of constraint to STP. It does this by tracking the relations between the different variables. Assume that a third condition $\alpha_c + \alpha_b > 50$ is added to our previous example. The resulting path condition would therefore be $\pi = \{\alpha_a = 10, \alpha_b < 30, \alpha_c + \alpha_b > 50\}$. If the next statement is $assert(c != 20)$, the query to STP would try to negate this assertion condition. Because the condition is not related to $\alpha_a$ the first contraint can be dropped completely for this query. This does not do any modification to the state data, but optimises only one specific query.\footnote{Note how this constraint only can be dropped because the second optimization removed $\alpha_a$ from the second condition. Otherwise a relation would still exist.}

The last and most complex optimization is called Counter-example Cache. In the cache each constraint set is saved together with a possible variable assignment if the query was successful, otherwise it will be marked as UNSAT. Before handing over a query to STP the cache is searched for a related superset or subset.

If a superset is found and this superset has a solution, the variable assignment also has to be satisfiable for the current condition set, because dropping of constraints can never invalidate a solution.

If a subset of the original query set is found and has no solution, this results in an unsatisiable solution as well. When there's no solution that satisfies the less strict subset, there's no way that any variable assignment can satify the queried set, which contains all of the constraints of the subset and some additional constraints.

If a subset is found and has a satifisfiable assignment there is a good chance that this solution will also satisify the new constraint set. Because it is much cheaper to verify if a solution is valid for a specific constraint set, KLEE does exactly that and returns the solution. If the solution is not valid for the new constraint set a query to STP is necessary.

The Counter-example Cache is especially powerful in combiniation with Constraint Independence because the queried constraint sets get smaller and therefore hit the cache more often.

In all this KLEE does nothing different than specified in the previous chapter \ref{section:symbolic_execution} and implements a specific and efficient memory and state managment, query optimization with caching and different state schedulings. But there's an additional topic that is tackled by KLEE.
\subsubsection{Dependency on environment}
Another problem of symbolic execution is the dependency on the environment as discussed in chapter \ref{section:symbolic_restrictions}. KLEE tries to loosen the limitations by introducing so called Environment Modeling. The idea behind these models is that they substitute the real environment against one that is aware of the symbolic input values. 
This model needs to be able to accept a symbolic value and produce every possible value from it. Additionally it needs to be aware of the previous modification that the program made on this model, but it's important that the modifications only affect the model in subsequent states. 

During the execution of KLEE these models will be injected based on the call that was made to the environment. These models are non trivial to write and require deep knowledge of the original function as they need to to behave like it. KLEE already includes a complete model for a symbolic file system and many different system calls like open, read, write, that operate on this model.
The filesystem model opitimizes concrete calls by dispatching it to the original function on the real file system if the call contains only concrete arguments. Only when a symbolic value is passed as an argument the related model will be called. It's required to specify the number and size of symbolic files separately when starting a KLEE-analysis, so that KLEE is able to allocate the files in the model and point the corresponding variable to the correct file.

At default settings KLEE's file system model does produce environmental failures such as disk full. However it's possible to simulate such failures, based on the requirements for the program. By offering such an option it's in the hands of the user to choose either more completeness or less computations. The same method can be applied to any model by only handling the cases which the user of KLEE want's to check. However he should always remember that by simplifying the model some of the completeness of the analysis vanishs.

\subsubsection{Testcases}
Whenever a state reaches the end of the program or an error is detected, KLEE generates a testcase. This is done by querying STP for a concrete assignment for all symbolic values under the current path condition. If the program is deterministic an execution of the original program with these concrete values will behave exactly as the symbolic execution with this path condition.
Note that it is no longer required to compile the program to LLVM. This has additional benefits, such as it's easy to measure coverage by using standard tooling such as gcov, or that it is easy to prove that a certain input triggers an error. To prove this a special setup is no longer required, the program has just to be run with the appropriate values.

Executing testcases which use a symbolic model is not trivial, because the environment has to be setup to reflect the symbolic model. Before executing the program KLEE creates the required files, directories, etc and calls the program with the new concrete file locations. Because it is not possible to reproduce an environmental failure, KLEE simulates this case whenever it is required. It uses a debugging tool to return the required error state and do not execute the system call at all.

\subsubsection{Software Equivalence}
\todo{maybe add tool equivalence, but it is in my opinion a rarely used scenario}
\subsection{Other approaches}
\todo{add other search strategies that are not used in KLEE}
\cite{SurveySymExec-CSUR18}